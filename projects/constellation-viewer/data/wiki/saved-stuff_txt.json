{
  "title": "saved-stuff_txt",
  "content": "# saved-stuff.txt\n\nContent-Type: text/x-zim-wiki\nWiki-Format: zim 0.6\nCreation-Date: 2024-07-23T15:42:25-07:00\n\n====== saved-stuff.txt ======\n--------------------\nRuntimeError                              Traceback (most recent call last)\n/tmp/ipykernel_451155/3295754042.py in <module>\n\t 11 tokenizer = AutoTokenizer.from_pretrained(\"togethercomputer/RedPajama-INCITE-Instruct-3B-v1\")\n\t 12 model = AutoModelForCausalLM.from_pretrained(\"togethercomputer/RedPajama-INCITE-Instruct-3B-v1\", torch_dtype=torch.float16)\n---> 13 model = model.to('cuda:0')  # Move the model to the GPU if available\n\t 14 \n\t 15 # Inference\n\n~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py in to(self, *args, **kwargs)\n   1876             )\n   1877         else:\n-> 1878             return super().to(*args, **kwargs)\n   1879 \n   1880     def half(self, *args):\n\n~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py in to(self, *args, **kwargs)\n   1143             return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n   1144 \n-> 1145         return self._apply(convert)\n   1146 \n   1147     def register_full_backward_pre_hook(\n\n~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py in _apply(self, fn)\n\t795     def _apply(self, fn):\n\t796         for module in self.children():\n--> 797             module._apply(fn)\n\t798 \n\t799         def compute_should_use_set_data(tensor, tensor_applied):\n\n~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py in _apply(self, fn)\n\t795     def _apply(self, fn):\n\t796         for module in self.children():\n--> 797             module._apply(fn)\n\t798 \n\t799         def compute_should_use_set_data(tensor, tensor_applied):\n\n~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py in _apply(self, fn)\n\t818             # `with torch.no_grad():`\n\t819             with torch.no_grad():\n--> 820                 param_applied = fn(param)\n\t821             should_use_set_data = compute_should_use_set_data(param, param_applied)\n\t822             if should_use_set_data:\n\n~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py in convert(t)\n   1141                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n   1142                             non_blocking, memory_format=convert_to_format)\n-> 1143             return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n   1144 \n   1145         return self._apply(convert)\n\n~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py in _lazy_init()\n\t245         if 'CUDA_MODULE_LOADING' not in os.environ:\n\t246             os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n--> 247         torch._C._cuda_init()\n\t248         # Some of the queued calls may reentrantly call _lazy_init();\n\t249         # we need to just return without initializing in that case.\n\nRuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n\n\n## Metadata\n- **Source**: All of it Anything Everything At Once/saved-stuff.txt.txt\n- **Type**: document\n- **Tags**: document, All_of_it_Anything_Everything_At_Once\n- **Imported**: 2025-05-05T16:25:37.193Z",
  "source": {
    "type": "notebook",
    "path": "All of it Anything Everything At Once/saved-stuff.txt.txt",
    "importedAt": "2025-05-05T16:25:37.193Z"
  },
  "created": "2025-05-05T16:25:37.193Z",
  "modified": "2025-05-05T16:25:37.193Z",
  "tags": [
    "document",
    "All_of_it_Anything_Everything_At_Once"
  ]
}