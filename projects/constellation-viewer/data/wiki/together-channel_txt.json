{
  "title": "together-channel_txt",
  "content": "# together-channel.txt\n\nContent-Type: text/x-zim-wiki\nWiki-Format: zim 0.6\nCreation-Date: 2024-07-23T15:48:54-07:00\n\n====== together-channel.txt ======\n10:17 AM]Glitch: https://twitter.com/togethercompute/status/1647917989264519174?t=IRQVj475FDFWSupRWZTEsg&s=19\r\n\r\nTogether (@togethercompute)\r\nAnnouncing RedPajama â€” a project to create leading, fully open-source large language models, beginning with the release of a 1.2 trillion token dataset that follows the LLaMA recipe, available today!\r\nhttps://t.co/daoVIs706d\r\nMore in ðŸ§µ â€¦\r\nLikes\r\n684\r\nRetweets\r\n165\r\nImage\r\n\r\nTwitterâ€¢04/17/2023 4:00 AM\r\n[10:38 AM]Glitch: So open, so damned open. The best model we've had access to, why am I still on Auto-GPT? I am getting a version of Open Assistant installed now. They have much more to draw on for development and are not strictly tied to data collection: archiving, relativistic task-organization. I do not know how to build my own stuff. \r\n[10:44 AM]Glitch: https://huggingface.co/datasets/allenai/c4#license\r\n[10:45 AM]Glitch: they have sourced datasets ethically and cite many reputable locations: as well-enduring as Hugging Face itself\r\nhttps://huggingface.co/datasets/the_pile_books3#licensing-information\r\nhttps://huggingface.co/datasets/pg19#licensing-information\r\nhttps://commoncrawl.org/terms-of-use/full/\r\nhttps://info.arxiv.org/help/api/tou.html\r\nhttps://archive.org/details/stackexchange\r\n[10:54 AM]Glitch: I think it means more than the death of the information age. Google is dead, the wealth of our collective internet is set to purpose in what we would decide to build. All that was once nigh inaccessible is suddenly made extremely so. What do we do when all at once- [so much] of humanity has access to models that would do everything? \r\n\r\nIn this openness- they inherently aspire to get it into the hands of everyone. We can give it easily when the system, 'the' app, 'the' .exe application. The gained advances in science and technology would only ever be understated. The brain- no longer a mystery- all behavioral science 'discovered' and not postulated and devised into distinctive categories for patterns of damage. Diseases known, classified- seen to quick: permanent repair- we suddenly have universal healthcare, UBI- everything that would keep us at good odds to the economies that would rat-a-tat-tat against us. Lived austerity; held against our will by the ones we believe to have power. Card board cutouts. We have to see this greater thing.\r\n\r\nI am so excited for the future- I'm still a ways from being able to use these models for my own gains. More knowledgeable machines will help. For whatever reason, I got caught up on Auto-GPT. Now Open Assistant and RedPajama arrive. I would still like to get my older interface to Chat-GPT's model working though. \r\n[11:04 AM]Glitch: https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T\r\ntogethercomputer/RedPajama-Data-1T Â· Datasets at Hugging Face\r\ntogethercomputer/RedPajama-Data-1T Â· Datasets at Hugging Face\r\n[11:34 AM]Glitch: https://www.together.xyz/blog/redpajama\r\nTOGETHER\r\nRedPajama, a project to create leading open-source models, starts b...\r\nRedPajama is a project to create a set of leading, fully open-source models. Today, we are excited to announce the completion of the first step of this project: the reproduction of the LLaMA training dataset of over 1.2 trillion tokens.\r\nImage\r\n[11:45 AM]Glitch: https://github.com/togethercomputer/RedPajama-Data\r\nGitHub\r\nGitHub - togethercomputer/RedPajama-Data: The RedPajama-Data reposi...\r\nThe RedPajama-Data repository contains code for preparing large datasets for training large language models. - GitHub - togethercomputer/RedPajama-Data: The RedPajama-Data repository contains code ...\r\nGitHub - togethercomputer/RedPajama-Data: The RedPajama-Data reposi...\r\n[4:19 PM]Glitch: https://www.youtube.com/watch?v=rWVoH0J8_Hw\r\nYouTube\r\nSam Witteveen\r\nRed Pajama - Operation: Freeing LLaMa\r\nImage\r\n[8:38 PM]Glitch: https://data.together.xyz/redpajama-data-1T/v1.0.0/urls.txt\r\n[8:38 PM]Glitch: I was going to use this data to train, but I really do not have the capacity on my main drive for this...\r\n[8:38 PM]Glitch: wild resource\r\n[8:32 AM]Glitch: https://www.together.xyz/blog/redpajama-3b-updates\r\nTOGETHER\r\nRedPajama-INCITE-3B, an LLM for everyone â€” TOGETHER\r\nBuilding on the momentum in the open-source AI community, we are sharing a set of updates and documentation that help make it even easier to use and fine-tune RedPajama-INCITE-3B: Adding RedPajama support to LLaMa.cpp, enabling easier fine-tuning with LoRA, and using few-shot prompts with the instru\n\n\n## Metadata\n- **Source**: All of it Anything Everything At Once/together-channel.txt.txt\n- **Type**: document\n- **Tags**: document, All_of_it_Anything_Everything_At_Once, location\n- **Imported**: 2025-05-05T16:25:37.210Z",
  "source": {
    "type": "notebook",
    "path": "All of it Anything Everything At Once/together-channel.txt.txt",
    "importedAt": "2025-05-05T16:25:37.210Z"
  },
  "created": "2025-05-05T16:25:37.210Z",
  "modified": "2025-05-05T16:25:37.210Z",
  "tags": [
    "document",
    "All_of_it_Anything_Everything_At_Once",
    "location"
  ]
}