{
  "title": "2301_07_608-Human-Timescale_Adaptation_in_an_Open-Ended_Task_Space_txt",
  "content": "# 2301.07.608-Human-Timescale_Adaptation_in_an_Open-Ended_Task_Space.txt\n\nContent-Type: text/x-zim-wiki\nWiki-Format: zim 0.6\nCreation-Date: 2024-07-23T14:49:21-07:00\n\n====== 2301.07.608-Human-Timescale Adaptation in an Open-Ended Task Space.txt ======\nPyramid in a Haystack was kinda lame. Like bad level design. They personify a lot but why confound the rules?\r\n\r\nThe 'Pass over the wall repeatedly' test was interesting to watch. I wonder why they act like that.\r\n\r\ntheir full site. really, really incredible work.\r\n\r\nhttps://sites.google.com/view/adaptive-agent/\r\n\r\nOpenGPT: [the rhetoric here is just as good as the paper]\r\nThe person is expressing that they wish there was more commentary on the paper about Deep Mind's AI, but they believe that the work is a fundamental breakthrough that will revolutionize the requirements for training neural networks. \r\n\r\nThe paper discusses training a reinforcement learning agent at scale, which leads to a general in-context learning algorithm that can adapt to novel problems as quickly as humans. The paper discusses the ingredients that lead to this adaptation and demonstrates the characteristic scaling laws with respect to network size, memory length, and richness of the training task distribution. The paper also includes a comparison to human performance. The person believes that these results lay the foundation for increasingly general and adaptive RL agents that perform well across ever-larger open-ended domains.\r\n\r\n[strictly regarding the conclusion]\r\nThe text discusses the ability of intelligent agents to adapt to new information across a range of timescales, and how reinforcement learning can be used to train large-scale, generally adaptive models. The paper presents an adaptive agent (AdA) that can rapidly adapt across a vast, open-ended task space, at a timescale similar to that of human players, through the use of black-box meta-RL and automatic curriculum techniques. \r\n\r\nThe paper demonstrates that attention-based architectures can take advantage of this signal much more effectively than purely recurrent networks, and provides a recipe for training a 500M parameter model that can pave the way for further advances in the intersection of RL and foundation models. The ultimate goal is to create models that can perform few-shot adaptation and fine-tuning on useful control problems in the real world.\r\n\r\nI'd recommend downloading the paper and having the default software read it aloud. This is dense.\r\n\r\nI'm listening to the paper now and the the AdA model has systems of regret, \"filtering, using a dynamic criteria (the lowest fitness value of the archive)\" being history dependent encoding as input. the model is rolled-\" extrapolate this to systems of hierarchical expression to ways of our behavior. The idea that we act on memory based representations of input. The thing of these behaviors are written in [3]D context. The text is almost scary. If these things represent our systemic- base interactions. No emotive or need-based intuitions. They mention the module Transformer-XL as the main architecture for these studies. \r\n\r\n[tasks have time constraints]\r\n\r\nGoing beyond few shots. \"We propose a simple modification to our Transformer-XL architecture in increase the effective memory length without additional computational cost. Since observations in visual RL environments tend to be highly temporally correlated, we propose sub-sampling the sequence as described for RNN with Attention\" I need mention that all tasks are set under time limits There are teachers policies mentioned. This text is so complicated. But so damn important. [important but it's a damn lot] [they've already TRAINED these machines with people! They said AdA was laggy! Listen to this study, something so damn important.] \n\n\n## Metadata\n- **Source**: All of it Anything Everything At Once/2301.07.608-Human-Timescale_Adaptation_in_an_Open-Ended_Task_Space.txt.txt\n- **Type**: document\n- **Tags**: document, All_of_it_Anything_Everything_At_Once, character-design, story\n- **Imported**: 2025-05-05T16:25:37.035Z",
  "source": {
    "type": "notebook",
    "path": "All of it Anything Everything At Once/2301.07.608-Human-Timescale_Adaptation_in_an_Open-Ended_Task_Space.txt.txt",
    "importedAt": "2025-05-05T16:25:37.035Z"
  },
  "created": "2025-05-05T16:25:37.035Z",
  "modified": "2025-05-05T16:25:37.035Z",
  "tags": [
    "document",
    "All_of_it_Anything_Everything_At_Once",
    "character-design",
    "story"
  ]
}