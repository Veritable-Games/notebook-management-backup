{
  "title": "thebrain-ha_txt",
  "content": "# thebrain-ha.txt\n\nContent-Type: text/x-zim-wiki\nWiki-Format: zim 0.6\nCreation-Date: 2024-07-23T15:47:07-07:00\n\n====== thebrain-ha.txt ======\n[11:05 PM]Glitch: Brain Criticality - Optimizing Neural Computations\r\nhttps://youtu.be/vwLb3XlPCB4\r\nYouTube\r\nArtem Kirsanov\r\nBrain Criticality - Optimizing Neural Computations\r\nImage\r\n[11:07 PM]Glitch: https://arxiv.org/abs/1010.2530\r\narXiv.org\r\nEmergent complex neural dynamics\r\nA large repertoire of spatiotemporal activity patterns in the brain is the\r\nbasis for adaptive behaviour. Understanding the mechanism by which the brain's\r\nhundred billion neurons and hundred trillion synapses manage to produce such a\r\nrange of cortical configurations in a flexible manner remains a fundamental\r\nproblem in neuroscience. One plausible...\r\nImage\r\n[11:09 PM]Glitch: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5816155/\r\nPubMed Central (PMC)\r\nLandau–Ginzburg theory of cortex dynamics: Scale-free avalanches em...\r\nThe human cortex operates in a state of restless activity, the meaning and functionality of which are still not understood. A fascinating, though controversial, hypothesis, partially backed by empirical evidence, suggests that the cortex might work at ...\r\nImage\r\n[11:45 PM]Glitch: https://en.m.wikipedia.org/wiki/Markov_blanket\r\nMarkov blanket\r\nIn statistics and machine learning, when one wants to infer a random variable with a set of variables, usually a subset is enough, and other variables are useless. Such a subset that contains all the useful information is called a Markov blanket. If a Markov blanket is minimal, meaning that it cannot drop any variable without losing information,...\r\nMarkov blanket\r\n[11:46 PM]Glitch: https://en.m.wikipedia.org/wiki/Bayesian_inference\r\nBayesian inference\r\nBayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics. Bayesian updating is particularly important in the dynamic ana...\r\n[12:41 AM]Glitch: https://en.m.wikipedia.org/wiki/Free_energy_principle\r\nFree energy principle\r\nThe free energy principle is a mathematical principle in biophysics and cognitive science (especially Bayesian approaches to brain function, but also some approaches to artificial intelligence). It describes a formal account of the representational capacities of physical systems: that is, why things that exist look as if they track properties of...\r\n[1:01 AM]Glitch: https://en.m.wikipedia.org/wiki/Structured_sparsity_regularization\r\nStructured sparsity regularization\r\nStructured sparsity regularization is a class of methods, and an area of research in statistical learning theory, that extend and generalize sparsity regularization learning methods. Both sparsity and structured sparsity regularization methods seek to exploit the assumption that the output variable\r\n\r\n\r\n\r\nY\r\n\r\n\r\n{\\dis...\r\n[1:02 AM]Glitch: https://link.springer.com/chapter/10.1007/978-981-16-9937-5_2\r\nSpringerLink\r\nGeneralization of Law of Requisite Variety\r\nThe purpose of the present research is to generalize and formulate Ashby’s Law of Requisite Variety in the context of a goal seeking system and its relevant environment in the framework of logico-mathematical general systems theory. The law, one of the most...\r\nImage\r\n[1:41 AM]Glitch: https://en.m.wikipedia.org/wiki/Wake-sleep_algorithm\r\nWake-sleep algorithm\r\nThe wake-sleep algorithm is an unsupervised learning algorithm for a stochastic multilayer neural network. The algorithm adjusts the parameters so as to produce a good density estimator. There are two learning phases, the “wake” phase and the “sleep” phase, which are performed alternately. It was first designed as a model for brain functioning u...\n\n\n## Metadata\n- **Source**: All of it Anything Everything At Once/thebrain-ha.txt.txt\n- **Type**: document\n- **Tags**: document, All_of_it_Anything_Everything_At_Once\n- **Imported**: 2025-05-05T16:25:37.208Z",
  "source": {
    "type": "notebook",
    "path": "All of it Anything Everything At Once/thebrain-ha.txt.txt",
    "importedAt": "2025-05-05T16:25:37.208Z"
  },
  "created": "2025-05-05T16:25:37.208Z",
  "modified": "2025-05-05T16:25:37.208Z",
  "tags": [
    "document",
    "All_of_it_Anything_Everything_At_Once"
  ]
}