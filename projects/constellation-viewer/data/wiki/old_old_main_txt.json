{
  "title": "old_old_main_txt",
  "content": "# old_old_main.txt\n\nContent-Type: text/x-zim-wiki\nWiki-Format: zim 0.6\nCreation-Date: 2024-07-23T15:26:59-07:00\n\n====== old old main.txt ======\nimport abc\r\nimport os\r\nimport openai\r\nimport yaml\r\nimport sys\r\n\r\nfrom dotenv import load_dotenv\r\nload_dotenv()\r\n\r\n# Load environment variables from .env file\r\n\r\nfrom abstract_singleton import AbstractSingleton\r\n\r\nclass Config(AbstractSingleton):\r\n\tdef __init__(self):\r\n\t\tsuper().__init__()\r\n\t\tself.openai_api_key = os.getenv(\"OPENAI_API_KEY\", None)\r\n\t\tself.temperature = float(os.getenv(\"TEMPERATURE\", 0.5))\r\n\t\tself.memory_index = os.getenv(\"MEMORY_INDEX\", 'auto-gpt')\r\n\t\tself.memory_backend = os.getenv(\"MEMORY_BACKEND\", 'local')\r\n\t\tself.redis_host = os.getenv(\"REDIS_HOST\", 'localhost')\r\n\t\tself.redis_port = os.getenv(\"REDIS_PORT\", \"6379\")\r\n\t\tself.redis_password = os.getenv(\"REDIS_PASSWORD\")\r\n\t\tself.redis_db = os.getenv(\"REDIS_DB\", '0')\r\n\t\tprint(f\"REDIS DB: {self.redis_db}\")\r\n\t\tself.smart_api_key = os.getenv(\"SMART_API_KEY\")\r\n\t\tself.smart_llm_model = os.getenv(\"SMART_LLM_MODEL\")\r\n\t\tself.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\r\n\t\tself.google_cse_id = os.getenv(\"GOOGLE_CSE_ID\")\r\n\t\tself.user_agent_header = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"}\r\n\r\n\t@staticmethod\r\n\tdef construct_full_prompt():\r\n\t\tprompt = \"Some prompt text\"\r\n\t\t# add more text to the prompt based on configuration options...\r\n\t\treturn prompt\r\n\t\r\n\t\t# Initialize the OpenAI API client\r\n\t\topenai.api_key = self.openai_api_key\r\n\r\n\t\t# Set the number of requests per minute for the OpenAI API\r\n\t\topenai.api_requestor.requests_per_minute = int(os.getenv('OPENAI_REQUESTS_PER_MINUTE', '120'))\r\n\r\n\tdef set_openai_api_key(self, value: str):\r\n\t\t\"\"\"Set the OpenAI API key.\"\"\"\r\n\t\tself.openai_api_key = value\r\n\t\topenai.api_key = value\r\n\r\n\t\tself.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\r\n\t\tself.redis_host = os.getenv(\"REDIS_HOST\", \"localhost\")\r\n\t\tself.redis_port = int(os.getenv(\"REDIS_PORT\", 6379))\r\n\t\tself.redis_password = os.getenv(\"REDIS_PASSWORD\", None)\r\n\t\tself.memory_backend = os.getenv(\"MEMORY_BACKEND\", \"local\")\r\n\t\tself.memory_index = os.getenv(\"MEMORY_INDEX\", \"auto-gpt\")\r\n\t\tself.memory_key_separator = os.getenv(\"MEMORY_KEY_SEPARATOR\", \"::\")\r\n\t\tself.max_history_length = int(os.getenv(\"MAX_HISTORY_LENGTH\", 3))\r\n\t\tself.max_response_length = int(os.getenv(\"MAX_RESPONSE_LENGTH\", 256))\r\n\t\tself.smart_llm_model = os.getenv(\"SMART_LLM_MODEL\", None)\r\n\t\tself.user_agent_header = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"}\r\n\r\n\tdef set_user_agent_header(self, value: str):\r\n\t\t\"\"\"Set the User-Agent header to use in API requests.\"\"\"\r\n\t\tself.user_agent_header = {\"User-Agent\": value}\r\n\r\n\tdef set_redis_host(self, value: str):\r\n\t\t\"\"\"Set the Redis server host.\"\"\"\r\n\t\tself.redis_host = value\r\n\r\n\tdef set_redis_port(self, value: int):\r\n\t\t\"\"\"Set the Redis server port.\"\"\"\r\n\t\tself.redis_port = value\r\n\r\n\tdef set_redis_db(self, value: int):\r\n\t\t\"\"\"Set the Redis database to use.\"\"\"\r\n\t\tself.redis_db = value\r\n\r\n\tdef set_memory_index(self, value: str):\r\n\t\t\"\"\"Set the Redis memory index.\"\"\"\r\n\t\tself.memory_index = value\r\n\r\n\tdef set_memory_backend(self, value: str):\r\n\t\t\"\"\"Set the memory backend.\"\"\"\r\n\t\tself.memory_backend = value\r\n\r\n\tdef set_openai_requests_per_minute(self, value: int):\r\n\t\t\"\"\"Set the number of requests per minute for the OpenAI API.\"\"\"\r\n\t\tprint(f\"MEMORY BACKEND: {self.memory_backend}\")\r\n\t\topenai.api_requestor.requests_per_minute = value\r\n\r\n\tdef get_openai_api_key(self) -> str:\r\n\t\t\"\"\"Get the OpenAI API key.\"\"\"\r\n\t\treturn self.openai_api_key\r\n\r\n\tdef get_user_agent_header(self) -> str:\r\n\t\t\"\"\"Get the User-Agent header.\"\"\"\r\n\t\treturn self.user_agent_header\r\n\r\n\tdef get_redis_host(self) -> str:\r\n\t\t\"\"\"Get the Redis server host.\"\"\"\r\n\t\treturn self.redis_host\r\n\r\n\tdef get_redis_port(self) -> int:\r\n\t\t\"\"\"Get the Redis server port.\"\"\"\r\n\t\treturn self.redis_port\r\n\r\n\tdef get_redis_db(self) -> int:\r\n\t\t\"\"\"Get the Redis database.\"\"\"\r\n\t\treturn self.redis_db\r\n\r\n\tdef get_memory_index(self) -> str:\r\n\t\t\"\"\"Get the Redis memory index.\"\"\"\r\n\t\treturn self.memory_index\r\n\r\n\tdef get_memory_backend(self) -> str:\r\n\t\t\"\"\"Get the memory backend.\"\"\"\r\n\t\treturn self\r\n\t\r\n\tdef get_azure_deployment_id_for_model(self, model: str) -> str:\r\n\t\t\"\"\"\r\n\t\tGet the Azure deployment ID for the given model.\r\n\r\n\t\t:param model: Name of the model.\r\n\t\t:return: Azure deployment ID.\r\n\t\t\"\"\"\r\n\t\tif model not in self.azure_deployment_ids:\r\n\t\t\traise ValueError(f\"Model {model} not found in azure_deployment_ids.\")\r\n\r\n\t\treturn self.azure_deployment_ids[model]\r\n\r\n\tdef set_google_api_key(self, value: str):\r\n\t\t\"\"\"\r\n\t\tSet the Google API key.\r\n\r\n\t\t:param value: Google API key.\r\n\t\t\"\"\"\r\n\t\tself.google_api_key = value\r\n\r\n\t\tself.use_mac_os_tts = True\r\n\t\tself.use_mac_os_tts = os.getenv(\"USE_MAC_OS_TTS\")\r\n\r\n\t\tself.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\r\n\t\tself.custom_search_engine_id = os.getenv(\"CUSTOM_SEARCH_ENGINE_ID\")\r\n\r\n\t\tself.pinecone_api_key = os.getenv(\"3b0a61d7-f207-4c53-96db-d93794c4270c\")\r\n\t\tself.pinecone_region = os.getenv(\"PINECONE_API_KEY\")\r\n\r\n\t\tself.image_provider = os.getenv(\"IMAGE_PROVIDER\")\r\n\t\tself.huggingface_api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\r\n\r\n\t\t# User agent headers to use when browsing web\r\n\t\t# Some websites might just completely deny request with an error code if no user agent was found.\r\n\t\tself.user_agent_header = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"}\r\n\t\tself.redis_host = os.getenv(\"REDIS_HOST\", \"localhost\")\r\n\t\tself.redis\r\n\t\tself.user_agent_header = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"}\r\n\t\tself.redis_host = os.getenv(\"REDIS_HOST\", \"localhost\")\r\n\t\tself.redis_port = os.getenv(\"REDIS_PORT\", \"6379\")\r\n\t\tself.redis_password = os.getenv(\"REDIS_PASSWORD\", \"\")\r\n\t\tself.wipe_redis_on_start = os.getenv(\"WIPE_REDIS_ON_START\", \"True\") == 'True'\r\n\t\tself.memory_index = os.getenv(\"MEMORY_INDEX\", 'auto-gpt')\r\n\t# Note that indexes must be created on db 0 in redis, this is not configurable.\r\n\r\n\t\tself.memory_backend = os.getenv(\"MEMORY_BACKEND\", 'local')\r\n\t\t# Initialize the OpenAI API client\r\n\t\topenai.api_key = self.openai_api_key\r\n\r\n\t# Set the number of requests per minute for the OpenAI API\r\n\topenai.api_requestor.requests_per_minute = int(os.getenv('OPENAI_REQUESTS_PER_MINUTE', '120'))\r\n\r\n\t# Set the backend for the LLM\r\n\tos.environ[\"LARGE_LM_BACKEND\"] = os.getenv(\"LARGE_LM_BACKEND\", \"gpt\")\r\n\t# Set the number of workers for the LLM\r\n\tos.environ[\"LARGE_LM_NUM_WORKERS\"] = os.getenv(\"LARGE_LM_NUM_WORKERS\", \"1\")\r\n\r\n\t# Set the path for the LLM models\r\n\tos.environ[\"LARGE_LM_PATH\"] = os.getenv(\"LARGE_LM_PATH\", \"llm-models\")\r\n\r\n\t# Set the cache size for the LLM\r\n\tos.environ[\"LARGE_LM_CACHE_SIZE\"] = os.getenv(\"LARGE_LM_CACHE_SIZE\", \"2000\")\r\n\r\n\t# Set the maximum length for the LLM\r\n\tos.environ[\"LARGE_LM_MAX_LEN\"] = os.getenv(\"LARGE_LM_MAX_LEN\", \"2048\")\r\n\r\n\t# Set the number of retries for HTTP requests\r\n\tos.environ[\"HTTP_RETRY_COUNT\"] = os.getenv(\"HTTP_RETRY_COUNT\", \"3\")\r\n\r\n\t# Set the backoff factor for HTTP retries\r\n\tos.environ[\"HTTP_RETRY_BACKOFF_FACTOR\"] = os.getenv(\"HTTP_RETRY_BACKOFF_FACTOR\", \"0.5\")\r\n\r\n\t# Set the maximum number of retries for HTTP requests\r\n\tos.environ[\"HTTP_RETRY_MAX_RETRIES\"] = os.getenv(\"HTTP_RETRY_MAX_RETRIES\", \"5\")\r\n\r\n\t# Set the timeout for HTTP requests\r\n\tos.environ[\"HTTP_REQUEST_TIMEOUT\"] = os.getenv(\"HTTP_REQUEST_TIMEOUT\", \"10\")\r\n\r\n\t# Set the timeout for HTTP connections\r\n\tos.environ[\"HTTP_CONNECTION_TIMEOUT\"] = os.getenv(\"HTTP_CONNECTION_TIMEOUT\", \"10\")\r\n\r\n\t# Set the retry status codes for HTTP retries\r\n\tos.environ[\"HTTP_RETRY_STATUS_CODES\"] = os.getenv(\"HTTP_RETRY_STATUS_CODES\", \"500,502,503,504,522,524,408\")\r\n\r\n\t# Set the logging level\r\n\tos.environ[\"LOG_LEVEL\"] = os.getenv(\"LOG_LEVEL\", \"INFO\")\r\n\r\n\t# Set the logging format\r\n\tos.environ[\"LOG_FORMAT\"] = os.getenv(\"LOG_FORMAT\", \"%(asctime)s - %(levelname)s - %(name)s - %(message)s\")\r\n\r\n\tdef update_from_env(self):\r\n\t\t\"\"\"\r\n\t\tUpdates the configuration from environment variables.\r\n\t\t\"\"\"\r\n\t\tself.debug_mode = os.getenv(\"DEBUG_MODE\", \"False\") == 'True'\r\n\t\tself.continuous_mode = os.getenv(\"CONTINUOUS_MODE\", \"False\") == 'True'\r\n\t\tself.continuous_limit = int(os.getenv(\"CONTINUOUS_LIMIT\", \"0\"))\r\n\t\tself.memory_backend = os.getenv(\"MEMORY_BACKEND\", 'local')\r\n\t\t\r\n\t\tdef __init__(self):\r\n\t\t\t\"\"\"Initialize the Config class\"\"\"\r\n\t\tself.debug_mode = False\r\n\t\tself.continuous_mode = False\r\n\t\tself.continuous_limit = 0\r\n\t\tself.speak_mode = False\r\n\r\n\t\tself.fast_llm_model = os.getenv(\"FAST_LLM_MODEL\", \"gpt-3.5-turbo\")\r\n\t\tself.smart_llm_model = os.getenv(\"SMART_LLM_MODEL\", \"gpt-4\")\r\n\t\tself.fast_token_limit = int(os.getenv(\"FAST_TOKEN_LIMIT\", 4000))\r\n\t\tself.smart_token_limit = int(os.getenv(\"SMART_TOKEN_LIMIT\", 8000))\r\n\r\n\t#print(self.openai_api_key)\r\n\t\r\n\t\tself.openai_api_key = os.getenv(\"OPEN_API_KEY\")\r\n\t\tself.temperature = float(os.getenv(\"TEMPERATURE\", \"1\"))\r\n\t\tself.use_azure = os.getenv(\"USE_AZURE\") == 'True'\r\n\t\tself.execute_local_commands = os.getenv('EXECUTE_LOCAL_COMMANDS', 'False') == 'True'\r\n\r\n\t\tif self.use_azure:\r\n\t\t\tself.load_azure_config()\r\n\t\t\topenai.api_type = self.openai_api_type\r\n\t\t\topenai.api_base = self.openai_api_base\r\n\t\t\topenai.api_version = self.openai_api_version\r\n\r\n\tdef set_elevenlabs_api_key(self, value: str):\r\n\t\t\t\"\"\"Set the ElevenLabs API key value.\"\"\"\r\n\t\t\tself.elevenlabs_api_key = value\r\n\r\n\tdef set_elevenlabs_voice_1_id(self, value: str):\r\n\t\t\t\"\"\"Set the ElevenLabs Voice 1 ID value.\"\"\"\r\n\t\t\tself.set_elevenlabs_voice_1_id = value\r\n\r\n\t\t\tself.elevenlabs_api_key = os.getenv(\"ELEVENLABS_API_KEY\")\r\n\t\t\tself.elevenlabs_voice_2_id = os.getenv(\"ELEVENLABS_VOICE_2_ID\")\r\n\r\n\t\t\tself.use_mac_os_tts = False\r\n\t\t\tuse_mac_os_tts = os.getenv(\"USE_MAC_OS_TTS\")\r\n\t\t\tif use_mac_os_tts is not None:\r\n\t\t\t\tself.use_mac_os_tts = use_mac_os_tts.lower() == \"true\"\r\n\r\n\t\t\tself.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\r\n\t\t\tself.custom_search_engine_id = os.getenv(\"CUSTOM_SEARCH_ENGINE_ID\")\r\n\r\n\t\t\tself.pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\r\n\t\t\tself.pinecone_region = os.getenv(\"PINECONE_REGION\")\r\n\r\n\t\t\tself.image_provider = os.getenv(\"IMAGE_PROVIDER\")\r\n\t\t\tself.huggingface_api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\r\n\r\n\t\t\t# User agent headers to use when browsing web\r\n\t\t\t# Some websites might just completely deny request with an error code if no user agent was found.\r\n\t\t\tself.user_agent_header = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"}\r\n\t\t\tself.redis_host = os.getenv(\"REDIS_HOST\", \"localhost\")\r\n\t\t\tself.redis_port = os.getenv(\"REDIS_PORT\", \"6379\")\r\n\t\t\tself.redis_password = os.getenv(\"REDIS_PASSWORD\", \"\")\r\n\t\t\tself.wipe_redis_on_start = os.getenv(\"WIPE_REDIS_ON_START\", \"True\") == 'True'\r\n\t\t\tself.memory_index = os.getenv(\"MEMORY_INDEX\", 'auto-g')\r\n\t\t\tself.memory_backend = os.getenv(\"MEMORY_BACKEND\", 'local')\r\n\t\t\t# Initialize the OpenAI API client\r\n\t\t\topenai.api_key = self.openai_api_key\r\n\r\nconfig = Config()\n\n\n## Metadata\n- **Source**: All of it Anything Everything At Once/old_old_main.txt.txt\n- **Type**: document\n- **Tags**: document, All_of_it_Anything_Everything_At_Once, story, quest, bug\n- **Imported**: 2025-05-05T16:25:37.154Z",
  "source": {
    "type": "notebook",
    "path": "All of it Anything Everything At Once/old_old_main.txt.txt",
    "importedAt": "2025-05-05T16:25:37.154Z"
  },
  "created": "2025-05-05T16:25:37.154Z",
  "modified": "2025-05-05T16:25:37.154Z",
  "tags": [
    "document",
    "All_of_it_Anything_Everything_At_Once",
    "story",
    "quest",
    "bug"
  ]
}