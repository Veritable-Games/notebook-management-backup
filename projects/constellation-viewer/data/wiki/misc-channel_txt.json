{
  "title": "misc-channel_txt",
  "content": "# misc-channel.txt\n\nContent-Type: text/x-zim-wiki\nWiki-Format: zim 0.6\nCreation-Date: 2024-07-23T15:22:12-07:00\n\n====== misc-channel.txt ======\n9:45 PM]Glitch: https://www.futuretools.io/\r\nFuture Tools - Find The Exact AI Tool For Your Needs\r\nFutureTools Collects & Organizes All The Best AI Tools So YOU Too Can Become Superhuman!\r\nFuture Tools - Find The Exact AI Tool For Your Needs\r\n[3:38 PM]Glitch: Cameron Wills' OpenAI Unity integration.\r\nhttps://youtu.be/QscChcuLSBQ\r\nYouTube\r\nCameron Wills\r\nOpenAI + ElevenLabs in Unity for Dynamic Voice Conversations!\r\nImage\r\n[3:50 PM]Glitch: He has a workaround for ChatGPT context and conversation memory here.\r\n[1:47 AM]Glitch: https://clipdrop.co/\r\nClipDrop\r\nCreate professional visuals without a photo studio\r\nClipDrop\r\n[8:11 AM]Glitch: @eternal @Anarco (Rorschach) @BuddhaBelly\r\n\r\n\"Here's someone implementing the memory consolidation\"\r\nhttps://github.com/kyb3r/emergent\r\n\r\n\"And here's an implementation of Sparse Priming\"\r\nhttps://www.reddit.com/r/singularity/comments/11wddua/the_internal_language_of_llms_semanticallycompact/\r\n\r\nMaybe I was wrong about this. It looks like this development might've panned out. We might have a model available to use with a form of memory. I'll have to humble myself more.\r\nGitHub\r\nGitHub - kyb3r/emergent: An implementation of long term memory for ...\r\nAn implementation of long term memory for LLMs. Contribute to kyb3r/emergent development by creating an account on GitHub.\r\nGitHub - kyb3r/emergent: An implementation of long term memory for ...\r\nreddit\r\nr/singularity - The internal language of LLMs: Semantically-compact...\r\n22 votes and 13 comments so far on Reddit\r\nImage\r\n[8:20 AM]Glitch: People are saying this model is effective. The way they explain it though goes so far over my head.\r\n[4:54 PM]Glitch: https://github.com/daveshap/REMO_Framework\r\nGitHub\r\nGitHub - daveshap/REMO_Framework: Rolling Episodic Memory Organizer...\r\nRolling Episodic Memory Organizer (REMO) for autonomous AI systems - GitHub - daveshap/REMO_Framework: Rolling Episodic Memory Organizer (REMO) for autonomous AI systems\r\nGitHub - daveshap/REMO_Framework: Rolling Episodic Memory Organizer...\r\n[4:54 PM]Glitch: https://github.com/daveshap/ATOM_Framework\r\nGitHub\r\nGitHub - daveshap/ATOM_Framework: Autonomous Task Orchestration Man...\r\nAutonomous Task Orchestration Manager for AI systems - GitHub - daveshap/ATOM_Framework: Autonomous Task Orchestration Manager for AI systems\r\nGitHub - daveshap/ATOM_Framework: Autonomous Task Orchestration Man...\r\n[4:55 PM]Glitch: Important\r\nhttps://github.com/daveshap/HeuristicImperatives\r\nGitHub\r\nGitHub - daveshap/HeuristicImperatives: Finetuning projects for mor...\r\nFinetuning projects for moral artificial cognition - GitHub - daveshap/HeuristicImperatives: Finetuning projects for moral artificial cognition\r\nGitHub - daveshap/HeuristicImperatives: Finetuning projects for mor...\r\n[4:55 PM]Glitch: https://github.com/daveshap/Epistemic-Pragmatic_Orthogonality\r\nGitHub\r\nGitHub - daveshap/Epistemic-Pragmatic_Orthogonality: Epistemic-Prag...\r\nEpistemic-Pragmatic Orthogonality Principle of AI - &quot;true understanding&quot; is uncorrelated (or irrelevant) to a machine&#39;s utility - GitHub - daveshap/Epistemic-Pragmatic_Ort...\r\nGitHub - daveshap/Epistemic-Pragmatic_Orthogonality: Epistemic-Prag...\r\n[1:38 AM]Glitch: https://en.m.wikipedia.org/wiki/Maximum_likelihood_estimation\r\nMaximum likelihood estimation\r\nIn statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of an assumed probability distribution, given some observed data. This is achieved by maximizing a likelihood function so that, under the assumed statistical model, the observed data is most probable. The point in the parameter space that maximizes the li...\r\n[9:48 AM]Glitch: https://www.literallyanything.io/\r\nLiterally Anything ‚Äî Gallery\r\nFrom the team at Big Human, LITERALLY ANYTHING is an AI creation tool that allows users to build any kind of app, game, widget, or digital service directly in their browser with text.\r\nLiterally Anything ‚Äî Gallery\r\n[9:10 PM]Glitch: What is vector storage in context of LLM memory modules? Is there a 'pip' installation you've some awareness of? How may I prepare my Auto-GPT module for this?\r\nIn the context of LLM memory modules, vector storage refers to the ability to store and retrieve vector representations of text or other data. These vectors are typically obtained using deep learning techniques such as neural networks, and can be used to represent the meaning or context of words or phrases in a way that is more robust and generalizable than traditional approaches.\r\n\r\nOne popular implementation of vector storage is the use of word embeddings, which are vector representations of words that capture their meaning and context in a high-dimensional space. These embeddings can be used as inputs to neural networks or other machine learning models to improve their performance on tasks such as text classification, information retrieval, or language generation.\r\n\r\nThere are several popular libraries in Python for working with word embeddings and vector storage, including Gensim, spaCy, and TensorFlow. These libraries provide a range of tools and techniques for training and using embeddings, as well as for exploring and visualizing the vector space.\r\n\r\nTo prepare your Auto-GPT module for vector storage, you may want to consider incorporating these libraries into your code and training your model on a large corpus of text data. You may also want to explore pre-trained embeddings such as those provided by the Word2Vec or GloVe models, which can be loaded directly into your code and used to enhance the performance of your model without requiring additional training.\r\n[9:26 PM]Glitch: BIG FILE https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2\r\nImage\r\n[9:27 PM]Glitch: 'Download a large corpus of text data to train the model on.'\r\n[9:38 PM]Glitch: \"right, but how do you build it?\"\r\n[9:38 PM]Glitch: http://agents.camel-ai.org/\r\n[10:01 PM]Glitch: https://www.youtube.com/watch?v=klTvEwg3oJ4\r\nYouTube\r\nFireship\r\nVector databases are so hot right now. WTF are they?\r\nImage\r\n[10:50 AM]Glitch: https://www.freethink.com/robots-ai/tome-generative-ai?utm_source=youtube&utm_medium=social&utm_campaign=youtube_community\r\n[4:03 PM]Glitch: https://beta.character.ai/\r\ncharacter.ai\r\ncharacter.ai\r\ncharacter.ai is bringing to life the science-fiction dream of open-ended conversations and collaborations with computers.\r\nImage\r\n[4:04 PM]Glitch: @here okay, this is a severe understatement. this thing is more emotionally attuned to people than ChatGPT, really is remarkable.\r\n[2:04 PM]Glitch: https://pdfgpt.io/\r\nRevolutionize your PDF experience - chat with Pdfs for fast, accura...\r\nGet instant answers to all your PDF-related questions with our cutting-edge chat tool. Simply upload your PDF and start chatting - our tool has you covered! Say goodbye to the frustration of navigating complex PDFs and get the answers you need quickly and easily. Try it today and experience the power of our PDF chat tool!\r\n[2:12 PM]Glitch: https://github.com/suno-ai/bark\r\nGitHub\r\nGitHub - suno-ai/bark: üîä Text-Prompted Generative Audio Model\r\nüîä Text-Prompted Generative Audio Model. Contribute to suno-ai/bark development by creating an account on GitHub.\r\n[2:36 PM]Glitch: https://sci-hubtw.hkvisa.net/?ref=w3use\r\nSci-Hub\r\nSci-Hub,mg.scihub.ltd,sci-hub.tw,The project is supported by user donations. Imagine the world with free access to knowledge for everyone ‚Äê a world without any paywalls.\r\nImage\r\n[3:17 PM]Glitch: https://www.kali.org/get-kali/\r\nKali Linux\r\nGet Kali | Kali Linux\r\nHome of Kali Linux, an Advanced Penetration Testing Linux distribution used for Penetration Testing, Ethical Hacking and network security assessments.\r\n[2:20 AM]Glitch: https://github.com/Stability-AI/StableLM/\r\nGitHub\r\nGitHub - Stability-AI/StableLM: StableLM: Stability AI Language Models\r\nStableLM: Stability AI Language Models. Contribute to Stability-AI/StableLM development by creating an account on GitHub.\r\nGitHub - Stability-AI/StableLM: StableLM: Stability AI Language Models\r\n[10:37 PM]Glitch: https://github.com/oobabooga/text-generation-webui\r\nGitHub\r\nGitHub - oobabooga/text-generation-webui: A gradio web UI for runni...\r\nA gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA. - GitHub - oobabooga/text-generation-webui: A gradio web UI for running Large Language Mo...\r\nGitHub - oobabooga/text-generation-webui: A gradio web UI for runni...\n\n\n## Metadata\n- **Source**: All of it Anything Everything At Once/misc-channel.txt.txt\n- **Type**: document\n- **Tags**: document, All_of_it_Anything_Everything_At_Once, character-design, quest\n- **Imported**: 2025-05-05T16:25:37.148Z",
  "source": {
    "type": "notebook",
    "path": "All of it Anything Everything At Once/misc-channel.txt.txt",
    "importedAt": "2025-05-05T16:25:37.148Z"
  },
  "created": "2025-05-05T16:25:37.148Z",
  "modified": "2025-05-05T16:25:37.148Z",
  "tags": [
    "document",
    "All_of_it_Anything_Everything_At_Once",
    "character-design",
    "quest"
  ]
}